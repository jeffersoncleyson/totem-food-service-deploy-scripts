name: "Totem Food Service"

on:
  workflow_dispatch:
    inputs:
      applicationState:
        description: 'Create or Delete application'
        required: true
        default: 'none'
        type: choice
        options:
        - create
        - delete
      customerName:
        description: 'Customer Name'
        required: true

permissions:
  id-token: write
  contents: read

jobs:
  terraform-modules:
    runs-on: ubuntu-latest
    env:
      TERRAFORM_COMPONENTS_DIR: "./totem-food-service-tf-module-components"
      TERRAFORM_INTEGRATION_DIR: "./totem-food-service-tf-module-integration-api-gateway-and-eks"
      HELM_CHART_DIR: "./totem-food-service-helm-chart"
      WHITE_SPACE: "#"
    steps:
      - uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false
      - uses: sergeysova/jq-action@v2
      - uses: actions/setup-node@v3
        with:
          node-version: 18

      - name: Check out the repo
        uses: actions/checkout@v3

      - name: Cloning terraform module API Gateway
        continue-on-error: false
        run: |
          git clone https://github.com/jeffersoncleyson/totem-food-service-tf-module-api-gateway.git -b main

      - name: Cloning terraform module EKS
        continue-on-error: false
        run: |
          git clone https://github.com/jeffersoncleyson/totem-food-service-tf-module-eks.git -b main

      - name: Cloning terraform module Login
        continue-on-error: false
        run: |
          git clone https://github.com/jeffersoncleyson/totem-food-service-tf-module-login.git -b main

      - name: Cloning terraform module Cognito
        continue-on-error: false
        run: |
          git clone https://github.com/jeffersoncleyson/totem-food-service-tf-module-cognito.git -b main

      - name: Cloning terraform module Authorizer
        continue-on-error: false
        run: |
          git clone https://github.com/jeffersoncleyson/totem-food-service-tf-module-authorizer.git -b main

      - name: Cloning terraform module components
        continue-on-error: false
        run: |
          git clone https://github.com/jeffersoncleyson/totem-food-service-tf-module-components.git -b main

      - name: Cloning terraform module integration API Gateway and EKS
        continue-on-error: false
        run: |
          git clone https://github.com/jeffersoncleyson/totem-food-service-tf-module-integration-api-gateway-and-eks.git -b main

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "arn:aws:iam::151403969336:role/oidc-github-actions"
          role-session-name: "oidc-github-actions"
          aws-region: ${{ vars.AWS_DEFAULT_REGION }}

      - name: Terraform Init components
        id: init
        continue-on-error: false
        run: |
          cat << EOF > ${{ env.TERRAFORM_COMPONENTS_DIR }}/terraform.tfvars.json
          {
            "application_name": "${{vars.APP_NAME}}", 
            "environment": "${{vars.ENVIRONMENT}}", 
            "owner_team": "${{vars.OWNER_TEAM}}",
            "region": "${{vars.AWS_DEFAULT_REGION}}"
          }
          EOF
          terraform -chdir=${{ env.TERRAFORM_COMPONENTS_DIR }} init -reconfigure

      - name: Install Lambda Authorizer Dependencies
        continue-on-error: false
        if: ${{ github.event.inputs.applicationState == 'create' }}
        run: |
          npm install --prefix ./totem-food-service-tf-module-authorizer/lambda
      
      - name: Install Lambda Login Dependencies
        continue-on-error: false
        if: ${{ github.event.inputs.applicationState == 'create' }}
        run: |
          npm install --prefix ./totem-food-service-tf-module-login/lambda

      - name: Terraform Plan components
        id: plan
        continue-on-error: false
        run: terraform -chdir=${{ env.TERRAFORM_COMPONENTS_DIR }} plan

      - name: Terraform Apply components
        id: apply
        if: ${{ github.event.inputs.applicationState == 'create' }}
        continue-on-error: false
        run: terraform -chdir=${{ env.TERRAFORM_COMPONENTS_DIR }} apply -auto-approve


      - name: Getting terraform componentes values
        continue-on-error: false
        run: |
          CLIENT_NAME=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key cognito_client_name)
          echo "CLIENT_NAME=$CLIENT_NAME" >> $GITHUB_ENV

          CLIENT_ID=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key cognito_client_id)
          echo "CLIENT_ID=$CLIENT_ID" >> $GITHUB_ENV

          USER_POOL_ID=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key cognito_user_pool_id)
          echo "USER_POOL_ID=$USER_POOL_ID" >> $GITHUB_ENV

          API_GATEWAY_STAGE_URL=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key api_gateway_url)
          echo "API_GATEWAY_STAGE_URL=$API_GATEWAY_STAGE_URL" >> $GITHUB_ENV

          API_GATEWAY_STAGE_URL_PAYMENT_CALLBACK=$API_GATEWAY_STAGE_URL/v1/totem/payment/callback
          echo "API_GATEWAY_STAGE_URL_PAYMENT_CALLBACK=$API_GATEWAY_STAGE_URL_PAYMENT_CALLBACK" >> $GITHUB_ENV

      - name: Getting AWS Cognito Client Secret
        continue-on-error: false
        run: |
          CLIENT_SECRET=$(. ./cognito_get_client_secret.sh --user-pool-id $USER_POOL_ID --client-name $CLIENT_NAME --client-id $CLIENT_ID)
          echo "CLIENT_SECRET=$CLIENT_SECRET" >> $GITHUB_ENV

      - name: Configuring EKS Context
        continue-on-error: false
        run: |
          CLUSTER_NAME=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key cluster_eks_name)
          . ./add_eks.sh --cluster-name $CLUSTER_NAME --region ${{ vars.AWS_DEFAULT_REGION }}

      - name: Configuring Auth Map
        continue-on-error: false
        if: ${{ github.event.inputs.applicationState == 'create' }}
        run: |
          sed -i 's/ACCOUND_ID/${{secrets.ACCOUND_ID}}/g' auth-map-template.yaml
          sed -i 's/APP_NAME/${{vars.APP_NAME}}/g' auth-map-template.yaml
          sed -i 's/SSO_ROLE/${{secrets.SSO_ROLE}}/g' auth-map-template.yaml
          sed -i 's/SSO_USERNAME/${{secrets.SSO_USERNAME}}/g' auth-map-template.yaml
          kubectl apply -f auth-map-template.yaml

      - name: Configuring EKS Namespace
        continue-on-error: false
        if: ${{ github.event.inputs.applicationState == 'create' }}
        run: |
          . ./add_namespace.sh --namespace ${{vars.NAMESPACE}}

      - name: Reload Core DNS
        if: ${{ github.event.inputs.applicationState == 'create' }}
        run: |
          ./restart_deployment.sh -dn coredns -n kube-system

      - name: Cloning Helm Chart Repository
        if: ${{ github.event.inputs.applicationState == 'create' }}
        continue-on-error: false
        run: |
          git clone https://github.com/jeffersoncleyson/totem-food-service-helm-chart.git -b main

      - name: Releasing Helm Charts
        if: ${{ github.event.inputs.applicationState == 'create' }}
        continue-on-error: false
        uses: WyriHaximus/github-action-helm3@v3
        with:
          exec: |
            MAILHOG_CHART=mailhog-chart
            . ./helm_chart_create_release.sh --release mailhog --dir $HELM_CHART_DIR/$MAILHOG_CHART --namespace ${{vars.NAMESPACE}}

            TOTEM_FOOD_RELEASE_NAME="${{ github.event.inputs.customerName }}"
            TOTEM_FOOD_CHART=totem-food-chart

            SUBCHART_CUSTOMER=totem-food-customer-service
            VALUES_TO_SET_CUSTOMER=$SUBCHART_CUSTOMER.image.tag=v4-beta,$SUBCHART_CUSTOMER.image.pullPolicy=Always,$SUBCHART_CUSTOMER.secrets.cognito.userPoolId=$USER_POOL_ID,$SUBCHART_CUSTOMER.secrets.cognito.clientId=$CLIENT_ID,$SUBCHART_CUSTOMER.secrets.cognito.clientSecret=$CLIENT_SECRET

            SUBCHART_ORDER=totem-food-order-service
            VALUES_TO_SET_ORDER=$SUBCHART_ORDER.image.tag=v4-beta,$SUBCHART_ORDER.image.pullPolicy=Always,$SUBCHART_ORDER.secrets.database.uri="\"${{ secrets.DB_URI }}\""

            SUBCHART_PAYMENT=totem-food-payment-service
            VALUES_TO_SET_PAYMENT=$SUBCHART_PAYMENT.image.tag=v4-beta,$SUBCHART_PAYMENT.image.pullPolicy=Always,secrets.payment.gateway.callback=$API_GATEWAY_STAGE_URL_PAYMENT_CALLBACK,secrets.payment.gateway.url=${{ vars.MERCADO_PAGO_PAYMENT_GATEWAY }},secrets.payment.gateway.store_id=${{ vars.STORE_ID }}secrets.payment.gateway.store_user_id=${{ vars.STORE_USER_ID }},secrets.payment.gateway.store_token_id="\"${{ secrets.STORE_TOKEN_ID }}\"",$SUBCHART_PAYMENT.secrets.database.uri="\"${{ secrets.DB_URI }}\""

            VALUES_TO_SET=$VALUES_TO_SET_ORDER,$VALUES_TO_SET_CUSTOMER,$VALUES_TO_SET_PAYMENT
            . ./helm_chart_create_release.sh --release $TOTEM_FOOD_RELEASE_NAME --dir $HELM_CHART_DIR/$TOTEM_FOOD_CHART --namespace ${{vars.NAMESPACE}} --values-to-set $VALUES_TO_SET --white-space $WHITE_SPACE


      - name: Getting Kubernetes Load Balancer value
        continue-on-error: false
        run: |
          sleep 30
          SVC_PRIVATE_LB_CUSTOMER="${{ github.event.inputs.customerName }}-tfc-svc-lb-private"
          DNS_NAME_CUSTOMER=$(. ./svc_get_load_balancer.sh --service-name $SVC_PRIVATE_LB_CUSTOMER --namespace ${{vars.NAMESPACE}})
          LB_ARN_CUSTOMER=$(. ./load_balancer_get_attributes.sh --region ${{ vars.AWS_DEFAULT_REGION }} --dns-name $DNS_NAME_CUSTOMER)
          LISTENER_ARN_CUSTOMER=$(. ./describe_load_balancer_lister.sh --region ${{ vars.AWS_DEFAULT_REGION }} --load-balancer-arn $LB_ARN_CUSTOMER)
          echo "LISTENER_ARN_CUSTOMER=$LISTENER_ARN_CUSTOMER" >> $GITHUB_ENV

          SVC_PRIVATE_LB_PAYMENT="${{ github.event.inputs.customerName }}-tfp-svc-lb-private"
          DNS_NAME_PAYMENT=$(. ./svc_get_load_balancer.sh --service-name $SVC_PRIVATE_LB_PAYMENT --namespace ${{vars.NAMESPACE}})
          LB_ARN_PAYMENT=$(. ./load_balancer_get_attributes.sh --region ${{ vars.AWS_DEFAULT_REGION }} --dns-name $DNS_NAME_PAYMENT)
          LISTENER_ARN_PAYMENT=$(. ./describe_load_balancer_lister.sh --region ${{ vars.AWS_DEFAULT_REGION }} --load-balancer-arn $LB_ARN_PAYMENT)
          echo "LISTENER_ARN_PAYMENT=$LISTENER_ARN_PAYMENT" >> $GITHUB_ENV

          SVC_PRIVATE_LB_ORDER="${{ github.event.inputs.customerName }}-tfo-svc-lb-private"
          DNS_NAME_ORDER=$(. ./svc_get_load_balancer.sh --service-name $SVC_PRIVATE_LB_ORDER --namespace ${{vars.NAMESPACE}})
          LB_ARN_ORDER=$(. ./load_balancer_get_attributes.sh --region ${{ vars.AWS_DEFAULT_REGION }} --dns-name $DNS_NAME_ORDER)
          LISTENER_ORDER_ARN=$(. ./describe_load_balancer_lister.sh --region ${{ vars.AWS_DEFAULT_REGION }} --load-balancer-arn $LB_ARN_ORDER)
          echo "LISTENER_ARN_ORDER=$LISTENER_ARN_ORDER" >> $GITHUB_ENV

      - name: Getting Integration values
        continue-on-error: false
        run: |
          CLUSTER_EKS_VPC_LINK=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key cluster_eks_vpc_link)
          echo "CLUSTER_EKS_VPC_LINK=$CLUSTER_EKS_VPC_LINK" >> $GITHUB_ENV

          CLUSTER_EKS_PRIVATE_SUBNET_ONE=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key cluster_eks_private_subnet_one)
          echo "CLUSTER_EKS_PRIVATE_SUBNET_ONE=$CLUSTER_EKS_PRIVATE_SUBNET_ONE" >> $GITHUB_ENV

          CLUSTER_EKS_PRIVATE_SUBNET_TWO=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key cluster_eks_private_subnet_two)
          echo "CLUSTER_EKS_PRIVATE_SUBNET_TWO=$CLUSTER_EKS_PRIVATE_SUBNET_TWO" >> $GITHUB_ENV
          
          API_GATEWAY_RESTRICT_API_ID=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key aws_apigatewayv2_api_restrict_api_id)
          echo "API_GATEWAY_RESTRICT_API_ID=$API_GATEWAY_RESTRICT_API_ID" >> $GITHUB_ENV
          
          API_GATEWAY_AUTORIZER_ID=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key aws_apigatewayv2_authorizer_authorizer_id)
          echo "API_GATEWAY_AUTORIZER_ID=$API_GATEWAY_AUTORIZER_ID" >> $GITHUB_ENV

          API_GATEWAY_VPC_LINK_ID=$(. ./value-from-terrafom.sh --dir $TERRAFORM_COMPONENTS_DIR --key aws_apigatewayv2_vpc_link_eks_id)
          echo "API_GATEWAY_VPC_LINK_ID=$API_GATEWAY_VPC_LINK_ID" >> $GITHUB_ENV

      - name: Terraform Init integration
        id: init_integration
        continue-on-error: false
        run: |
          cat << EOF > ${{ env.TERRAFORM_INTEGRATION_DIR }}/terraform.tfvars.json
          {
            "application_name": "${{ vars.APP_NAME }}", 
            "environment": "${{ vars.ENVIRONMENT }}", 
            "owner_team": "${{ vars.OWNER_TEAM }}",
            "region": "${{ vars.AWS_DEFAULT_REGION }}",
            "vpc_security_group_eks_ids": ["${{ env.CLUSTER_EKS_VPC_LINK }}"], 
            "eks_private_subnet_ids": ["${{ env.CLUSTER_EKS_PRIVATE_SUBNET_ONE }}", "${{ env.CLUSTER_EKS_PRIVATE_SUBNET_TWO }}"], 
            "eks_private_load_balancer_arn_customer": "${{ env.LISTENER_ARN_CUSTOMER }}",
            "eks_private_load_balancer_arn_payment": "${{ env.LISTENER_ARN_PAYMENT }}",
            "eks_private_load_balancer_arn_order": "${{ env.LISTENER_ARN_ORDER }}",
            "aws_apigatewayv2_api_restrict_api_id": "${{ env.API_GATEWAY_RESTRICT_API_ID }}",
            "aws_apigatewayv2_authorizer_authorizer_id": "${{ env.API_GATEWAY_AUTORIZER_ID }}",
            "aws_apigatewayv2_vpc_link_eks_id": "${{ env.API_GATEWAY_VPC_LINK_ID }}"
          }
          EOF
          terraform -chdir=${{ env.TERRAFORM_INTEGRATION_DIR }} init -reconfigure

      - name: Terraform Plan integration
        id: plan_integration
        continue-on-error: false
        run: terraform -chdir=${{ env.TERRAFORM_INTEGRATION_DIR }} plan

      - name: Terraform Apply integration
        id: apply_integration
        if: ${{ github.event.inputs.applicationState == 'create' }}
        continue-on-error: false
        run: terraform -chdir=${{ env.TERRAFORM_INTEGRATION_DIR }} apply -auto-approve

      - name: Terraform Destroy
        id: destroy
        if: ${{ github.event.inputs.applicationState == 'delete' }}
        continue-on-error: false
        run: |
          TOTEM_FOOD_RELEASE_NAME="${{ github.event.inputs.customerName }}"
          . ./helm_chart_delete_release.sh --release $TOTEM_FOOD_RELEASE_NAME --namespace ${{vars.NAMESPACE}}
          . ./helm_chart_delete_release.sh --release mailhog --namespace ${{vars.NAMESPACE}}
          terraform -chdir=$TERRAFORM_INTEGRATION_DIR destroy -auto-approve
          terraform -chdir=$TERRAFORM_COMPONENTS_DIR destroy -auto-approve

